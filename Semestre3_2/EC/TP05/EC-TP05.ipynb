{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia do Conhecimento 2022/2023\n",
    "\n",
    "## TP05: A Brief introduction to Naive Bayes \n",
    "\n",
    "*A Machine Learning Tutorial by Andre Falcao (DI/FCUL 2020-2022)*\n",
    "*revised by Catia Pesquita (DI/FCUL 2022-2023)*\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. Introduction to Naive-Bayes using Categorical Naive Bayes\n",
    "2. Naive Bayes in Scikit-learn\n",
    "3. Gaussian Naive-Bayes\n",
    "\n",
    "\n",
    "## 1. Introduction to Na√Øve Bayes\n",
    "\n",
    "Let's start with a very simple example. We have a dataset of 14 individuals who underwent rapid tests for Covid, from different brands (Teste_A and Teste_B) These individuals were then evaluated with an effective PCR test that actually said whether or not they were carriers of the SARS-Cov2 Virus.\n",
    "\n",
    "The results are in the covid.txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste_A</th>\n",
       "      <th>Teste_B</th>\n",
       "      <th>Covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Teste_A Teste_B Covid\n",
       "0        P       P     P\n",
       "1        P       P     P\n",
       "2        P       N     N\n",
       "3        N       N     N\n",
       "4        N       N     N\n",
       "5        N       P     N\n",
       "6        N       P     P\n",
       "7        N       P     N\n",
       "8        P       P     P\n",
       "9        N       N     N\n",
       "10       P       N     P\n",
       "11       N       N     N\n",
       "12       N       P     N\n",
       "13       N       P     N"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_covid=pd.read_csv(\"covid.txt\", sep=\"\\t\")\n",
    "\n",
    "df_covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Basic concepts and Bayes' Theorem\n",
    "\n",
    "Let's try to answer the following questions:\n",
    "1. What is the prevalence of infected with covid?\n",
    "2. What is the probability that an individual who tested positive in Test B is actually positive for Covid\n",
    "3. What is the probability that an individual who has Covid will be positive on the B test? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 prevalence of Covid\n",
    "The first question we can ask is to identify the prevalence of COVID in the sample\n",
    "\n",
    "$P(Covid_+)=\\frac{N_{pos}}{N}$\n",
    "\n",
    "The prevalence of a given class is also called *prior* because it has to do with our belief *a priori* of the proportion of individuals of each class in the population, not knowing anything else about each individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of positives is:  0.3571\n",
      "Prevalence of negatives is:  0.6429\n"
     ]
    }
   ],
   "source": [
    "N=df_covid.shape[0] #number of instances or individuals\n",
    "N_covid=df_covid[ df_covid.Covid==\"P\"].index.shape[0] #number of positive individuals\n",
    "N_ncovid=df_covid[df_covid.Covid==\"N\"].index.shape[0] #number of negative individuals\n",
    "P_covid=N_covid/N\n",
    "P_ncovid=N_ncovid/N\n",
    "\n",
    "print(\"Prevalence of positives is: %7.4f\" %P_covid)\n",
    "print(\"Prevalence of negatives is: %7.4f\" %P_ncovid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.1.2. Identify relationship between having a test result and diagnosis\n",
    "\n",
    "What is the probability that an individual who tested positive on the A test is in fact positive for Covid?\n",
    "\n",
    "What we are defining is the probability of an individual being positive if the test is positive, that is, among all individuals who had a positive A test, what fraction were in fact positive:\n",
    "\n",
    "$P(Covid_+ | A_+)=\\frac{P(Covid_+ \\cap A_+)}{P(A_+)}$\n",
    "\n",
    "$P(Covid_- | A_+)=\\frac{P(Covid_- \\cap A_+)}{P(A_+)}$\n",
    "\n",
    "$P(A_+)$\n",
    "\n",
    "$P(Covid_- \\cap A_+)$\n",
    "\n",
    "What we are actually saying here is **how much will I update my conviction** that the individual is Positive **if I actually have the evidence** that test A was positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that someone who had the A Positive test           HAS Covid is  0.8000\n",
      "The probability that someone who had the A Positive test DOES NOT HAVE Covid is  0.2000\n"
     ]
    }
   ],
   "source": [
    "#number of positive individuals with a positive test A\n",
    "N_covid_Ap =df_covid[(df_covid.Covid==\"P\") & (df_covid.Teste_A==\"P\")].index.shape[0] \n",
    "\n",
    "#number of negative individuals with a positive test A\n",
    "N_ncovid_Ap=df_covid[(df_covid.Covid==\"N\") & (df_covid.Teste_A==\"P\")].index.shape[0]\n",
    "\n",
    "#number of individuals with a positive test A\n",
    "N_Ap= df_covid[(df_covid.Teste_A==\"P\")].index.shape[0]\n",
    "\n",
    "print(\"The probability that someone who had the A Positive test           HAS Covid is %7.4f\" % (N_covid_Ap/N_Ap))\n",
    "print(\"The probability that someone who had the A Positive test DOES NOT HAVE Covid is %7.4f\" % (N_ncovid_Ap/N_Ap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Test B the procedure is the same, but even then if it seems that test B is \"useless\", notice that our prior conviction gets updated from 0.357 to 0.500, which is actually substantial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that someone who had the B Positive test           HAS Covid is  0.5000\n",
      "The probability that someone who had the B Positive test DOES NOT HAVE Covid is  0.5000\n"
     ]
    }
   ],
   "source": [
    "N_covid_Bp =df_covid[(df_covid.Covid==\"P\") & (df_covid.Teste_B==\"P\")].index.shape[0]\n",
    "N_ncovid_Bp=df_covid[(df_covid.Covid==\"N\") & (df_covid.Teste_B==\"P\")].index.shape[0]\n",
    "N_Bp= df_covid[(df_covid.Teste_B==\"P\")].index.shape[0]\n",
    "\n",
    "\n",
    "print(\"The probability that someone who had the B Positive test           HAS Covid is %7.4f\" % (N_covid_Bp/N_Bp))\n",
    "print(\"The probability that someone who had the B Positive test DOES NOT HAVE Covid is %7.4f\" % (N_ncovid_Bp/N_Bp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3. Identify relationship between a covid diagnosis and a test result\n",
    "\n",
    "\n",
    "As an example: What is the probability that an individual who has Covid will test positive on the A test? What we are representing here is, within individuals with positive Covid, which fraction was positive in test A. So what we want to represent is \n",
    "\n",
    "\n",
    "$P(A_+|Covid_+ )=\\frac{P(Covid_+ \\cap A_+)}{P(Covid_+)}$\n",
    "\n",
    "$P(A_-|Covid_+ )=\\frac{P(Covid_+ \\cap A_-)}{P(Covid_+)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that someone who HAS Covid will test A POSITIVE is :  0.8000\n",
      "The probability that someone who HAS Covid will test A NEGATIVE is :  0.2000\n"
     ]
    }
   ],
   "source": [
    "#number of positive individuals with a positive test A\n",
    "N_Ap_covid=df_covid[(df_covid.Covid==\"P\") & (df_covid.Teste_A==\"P\")].index.shape[0]\n",
    "\n",
    "#number of positive individuals with a negative test A\n",
    "N_An_covid=df_covid[(df_covid.Covid==\"P\") & (df_covid.Teste_A==\"N\")].index.shape[0]\n",
    "\n",
    "L_Ap_covid=N_Ap_covid/N_covid #probability of testing positive on test A if you have covid\n",
    "L_An_covid=N_An_covid/N_covid #probability of testing negative on test A if you have covid\n",
    "\n",
    "print(\"The probability that someone who HAS Covid will test A POSITIVE is : %7.4f\" %L_Ap_covid)\n",
    "print(\"The probability that someone who HAS Covid will test A NEGATIVE is : %7.4f\" %L_An_covid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for test B, we may have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that someone who HAS Covid will test B POSITIVE is :  0.8000\n",
      "The probability that someone who HAS Covid will test B NEGATIVE is :  0.2000\n"
     ]
    }
   ],
   "source": [
    "N_Bp_covid=df_covid[(df_covid.Covid==\"P\") & (df_covid.Teste_B==\"P\")].index.shape[0]\n",
    "N_Bn_covid=df_covid[(df_covid.Covid==\"P\") & (df_covid.Teste_B==\"N\")].index.shape[0]\n",
    "\n",
    "L_Bp_covid = N_Bp_covid/N_covid\n",
    "L_Bn_covid = N_Bn_covid/N_covid\n",
    "\n",
    "print(\"The probability that someone who HAS Covid will test B POSITIVE is : %7.4f\" % L_Bp_covid)\n",
    "print(\"The probability that someone who HAS Covid will test B NEGATIVE is : %7.4f\" % L_Bn_covid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4. Bayes Theorem\n",
    "\n",
    "The values above are the Likelihoods and are related to the Posterior by the union of both equations. For the case of the positive A test and positive Covid, we have the likelihood:\n",
    "\n",
    "$P(A_+|Covid_+ )=\\dfrac{P(Covid_+ \\cap A_+)}{P(Covid_+)}$\n",
    "\n",
    "and also the posterior:\n",
    "\n",
    "$P(Covid_+ | A_+)=\\dfrac{P(Covid_+ \\cap A_+)}{P(A_+)}$\n",
    "\n",
    "\n",
    "Therefore, it is not difficult to relate the two terms, being able to calculate the posterior according to the likelihood and the priors of the classes and categories of the variable:\n",
    "\n",
    "$P(Covid_+ | A_+)=\\dfrac{P( A_+ | Covid_+ ).P(Covid_+)}{P(A_+)}$\n",
    "\n",
    "This last expression is one of the most common representations of Bayes' Theorem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated Posterior of having Covid having a POSITIVE in test A is:   0.8000\n",
      "The calculated Posterior of having Covid having a POSITIVE in test B is:   0.5000\n"
     ]
    }
   ],
   "source": [
    "#priors of each class\n",
    "P_Ap= N_Ap/N #probability of having a positive test A\n",
    "P_Bp= N_Bp/N #probability of having a positive test B\n",
    "\n",
    "#Posteriors computed according to Bayes\n",
    "P_Covid_Ap = (L_Ap_covid * P_covid)/P_Ap #probability of having COVID with a positive on Test A\n",
    "P_Covid_Bp = (L_Bp_covid * P_covid)/P_Bp  #probability of having COVID with a positive on Test B\n",
    "\n",
    "print(\"The calculated Posterior of having Covid having a POSITIVE in test A is:  %7.4f\" %P_Covid_Ap)\n",
    "print(\"The calculated Posterior of having Covid having a POSITIVE in test B is:  %7.4f\" %P_Covid_Bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Naive Bayes\n",
    "\n",
    "The central idea in Naive Bayes is that as we can never have a population large enough to calculate the marginal probabilities of all combinations of factors, and **if we assume that the variables are independent**, we can multiply the likelihoods of the variables involved and apply the prior of the class to obtain an estimate of the *posterior* and choose among the obtained values, which one gives the highest value (Maximum a posteriori - MAP)\n",
    "\n",
    "So for the above problem, the probability of someone having a Positive on the 2 tests, assuming that test A and test B are independent is\n",
    "\n",
    "Probability that someone **has in fact** Covid:\n",
    "\n",
    "$P(Covid_+ | A_+, B_+) \\propto P(A_+ |Covid_+ ).P(B_+ |Covid_+ ).P(Covid_+)$\n",
    "\n",
    "Probability that someone **does not have**  Covid:\n",
    "\n",
    "\n",
    "$P(Covid_- | A_+, B_+) \\propto P(A_+ |Covid_- ).P(B_+ |Covid_- ).P(Covid_-)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individuals who do not have covid and test positive on test A:  1\n",
      "individuals who do not have covid and test positive on test B:  4\n",
      "The probability that someone who had both positive tests           HAS Covid is :  0.8780\n",
      "The probability that someone who had both positive tests DOES NOT HAVE Covid is :  0.1220\n"
     ]
    }
   ],
   "source": [
    "#we will first need to calculate the likelihood associated with not having covid and having positive tests \n",
    "\n",
    "#number of individuals who do not have covid and test positive on test A\n",
    "N_Ap_ncovid=df_covid[(df_covid.Covid==\"N\") & (df_covid.Teste_A==\"P\")].index.shape[0]  \n",
    "print(\"individuals who do not have covid and test positive on test A: \", N_Ap_ncovid)\n",
    "\n",
    "#number of individuals who do not have covid and test positive on test B\n",
    "N_Bp_ncovid=df_covid[(df_covid.Covid==\"N\") & (df_covid.Teste_B==\"P\")].index.shape[0]\n",
    "print(\"individuals who do not have covid and test positive on test B: \", N_Bp_ncovid)\n",
    "\n",
    "L_Ap_ncovid=N_Ap_ncovid/N_ncovid #probability(likelihood) of having a positive on test A and not having covid\n",
    "L_Bp_ncovid=N_Bp_ncovid/N_ncovid #probability(likelihood) of having a positive on test B and not having covid\n",
    "\n",
    "P_pp_covid =  L_Ap_covid  *  L_Bp_covid   * P_covid #probability of testing positive on both tests and having covid\n",
    "P_pp_ncovid = L_Ap_ncovid *  L_Bp_ncovid  * P_ncovid #probability of testing positive on both tests and not having covid\n",
    "\n",
    "#scale factor for getting probabilities\n",
    "S=P_pp_covid + P_pp_ncovid\n",
    "\n",
    "print(\"The probability that someone who had both positive tests           HAS Covid is : %7.4f\" % (P_pp_covid/S))\n",
    "print(\"The probability that someone who had both positive tests DOES NOT HAVE Covid is : %7.4f\" % (P_pp_ncovid/S))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "1.1. Calculate how likely is someone to have covid if they have both negative tests?\n",
    "\n",
    "1.2. Calculate how likely is someone to have covid if they have test A positive and test B negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HINT: to solve the exercise, we need to calculate the likelihood of the test being negative and not having covid \n",
    "N_An_ncovid=df_covid[(df_covid.Covid==\"N\") & (df_covid.Teste_A==\"N\")].index.shape[0]\n",
    "N_Bn_ncovid=df_covid[(df_covid.Covid==\"N\") & (df_covid.Teste_B==\"N\")].index.shape[0]\n",
    "\n",
    "L_An_ncovid=N_An_ncovid/N_ncovid\n",
    "L_Bn_ncovid=N_Bn_ncovid/N_ncovid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that someone who had both negatives tests           HAS Covid is :  0.0431\n",
      "The probability that someone who had both negatives tests DOES NOT HAVE Covid is :  0.9569\n"
     ]
    }
   ],
   "source": [
    "#solving exercise 1.1\n",
    "\n",
    "# just compute the posteriors. uncomment and complete:\n",
    "P_nn_ncovid = L_An_ncovid * L_Bn_ncovid * P_ncovid\n",
    "P_nn_covid  = L_An_covid * L_Bn_covid * P_covid\n",
    "\n",
    "#scale factor for getting probabilities\n",
    "#uncomment to run:\n",
    "S = P_nn_covid + P_nn_ncovid\n",
    "\n",
    "print(\"The probability that someone who had both negatives tests           HAS Covid is : %7.4f\" % (P_nn_covid/S))\n",
    "print(\"The probability that someone who had both negatives tests DOES NOT HAVE Covid is : %7.4f\" % (P_nn_ncovid/S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that someone who had A positive and B negative tests           HAS Covid is :  0.5902\n",
      "The probability that someone who had A positive and B negative tests DOES NOT HAVE Covid is :  0.4098\n"
     ]
    }
   ],
   "source": [
    "#solving exercise 1.2\n",
    "\n",
    "P_pn_ncovid = L_Ap_ncovid * L_Bn_ncovid * P_ncovid\n",
    "P_pn_covid  = L_Ap_covid * L_Bn_covid * P_covid\n",
    "\n",
    "S = P_pn_covid + P_pn_ncovid\n",
    "\n",
    "print(\"The probability that someone who had A positive and B negative tests           HAS Covid is : %7.4f\" % (P_pn_covid/S))\n",
    "print(\"The probability that someone who had A positive and B negative tests DOES NOT HAVE Covid is : %7.4f\" % (P_pn_ncovid/S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. A very simple Naive Bayes implementation for categorical data\n",
    "\n",
    "As you can see, Naive Bayes only needs 2 components:\n",
    "* An estimate of the prevalences (priors)\n",
    "* A separate likelihood estimate for each column of the data\n",
    "\n",
    "\n",
    "The \"fit\" of the Naive Bayes is just calculating these statistics directly from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PD_NB(X, y):\n",
    "    N, M=X.shape\n",
    "    \n",
    "    #first compute the priors\n",
    "    \n",
    "    #yv: the classes (N, P)\n",
    "    #yc: the number of individuals in each class\n",
    "    yv, yc=np.unique(y, return_counts=True) \n",
    "    \n",
    "    \n",
    "    #for each output class, calculate the prior as the frequency of each class. \n",
    "    #in this case 9/14 and 5/14\n",
    "    priors={yv[i]: yc[i]/sum(yc) for i in range(len(yv)) }\n",
    "\n",
    "    \n",
    "    #Now the likelihoods\n",
    "    #Can be read as \n",
    "    # L[i, \"B\" \"A\"] P(Xi =B | Y = A) \n",
    "    L_hoods={}\n",
    "    for j in range(M): #for each feature (i.e., each test result)\n",
    "        xs=np.unique(X[:,j])\n",
    "        for v in xs: #for each value of the feature (i.e., P or N)\n",
    "            for yi in yv: L_hoods[(j, v,  yi)]=0.0 #prepare the likelihoods dictionary, where the key is (feature, value, output class) \n",
    "    #for each output class\n",
    "    for yi in yv:\n",
    "        X_c = X[y==yi] #get the individuals from each class\n",
    "        #...now search each individual X column\n",
    "        for j in range(M):  #for each feature (i.e., each test result)\n",
    "            col = X_c[:,j] #get feature values\n",
    "            #vs: the values\n",
    "            #cs: the counts of each value\n",
    "            vs, cs = np.unique(col, return_counts=True)\n",
    "            # ...for each possible value\n",
    "            for i, v in enumerate(vs):\n",
    "                L_hoods[(j, v,  yi)] = cs[i]/np.sum(cs) #probability of a given value\n",
    "    \n",
    "\n",
    "    return priors, L_hoods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Displaying the model\n",
    "\n",
    "Let's create a simplified function for viewing priors and likelyhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors are:\n",
      "\tP(Y = N) =  0.6429\n",
      "\tP(Y = P) =  0.3571\n",
      "Likelyhoods:\n",
      "\tP(X0 = N | Y = N) =  0.8889\n",
      "\tP(X0 = N | Y = P) =  0.2000\n",
      "\tP(X0 = P | Y = N) =  0.1111\n",
      "\tP(X0 = P | Y = P) =  0.8000\n",
      "\tP(X1 = N | Y = N) =  0.5556\n",
      "\tP(X1 = N | Y = P) =  0.2000\n",
      "\tP(X1 = P | Y = N) =  0.4444\n",
      "\tP(X1 = P | Y = P) =  0.8000\n"
     ]
    }
   ],
   "source": [
    "#this function just prints the visualization of the priors and likelihoods\n",
    "def show_NB(priors, L_hoods):\n",
    "    print(\"Priors are:\")\n",
    "    for yi in priors:\n",
    "        print(\"\\tP(Y = %s) = %7.4f\" % (yi, priors[yi]))\n",
    "    print(\"Likelyhoods:\")\n",
    "    for i, xi, yi in L_hoods:\n",
    "        print(\"\\tP(X%d = %s | Y = %s) = %7.4f\" % (i, xi, yi, L_hoods[(i,xi,yi)]))\n",
    "\n",
    "        \n",
    "X = df_covid.values[:,(0,1)]\n",
    "y = df_covid.values[:,2]\n",
    "\n",
    "priors, L_hoods=PD_NB(X,y)\n",
    "show_NB(priors, L_hoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. The Naive-Bayes classifier\n",
    "\n",
    "We can use the information calculated for each of the variables (priors and likelihood) to make estimates, by simply applying the Naive Bayes simplification that assumes the independence of the variables by multiplying the priors and likelihood associated with each column of the data. \n",
    "\n",
    "#### Exercise 2\n",
    "1. Identify in the code below by commenting each line: \n",
    "    * How the likelihoods are used\n",
    "    * how the priors are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data: an individual described by their features (here test results)\n",
    "\n",
    "\n",
    "def calc_posterior(data, priors, L_hoods):\n",
    "    print(data)\n",
    "    \n",
    "    probs=np.zeros(len(priors))\n",
    "\n",
    "    for j, yp in enumerate(priors.keys()):\n",
    "        probs[j]=priors[yp]\n",
    "        for i, d in enumerate(data): probs[j]*=L_hoods[(i, d, yp)]\n",
    "    #scaling to 1.0\n",
    "    probs=probs/np.sum(probs)\n",
    "    return {yp: probs[j] for j, yp in enumerate(priors.keys())}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that we have a set of observations for which we want to calculate the probabilities of a class, we just have to see the calculated probabilities and choose the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N']\n",
      "Case  ['N', 'N']\n",
      "\tP(Y = N | X=['N', 'N'] )=  0.9569\n",
      "\tP(Y = P | X=['N', 'N'] )=  0.0431\n",
      "\t==> Best is: N\n",
      "['N', 'P']\n",
      "Case  ['N', 'P']\n",
      "\tP(Y = N | X=['N', 'P'] )=  0.8163\n",
      "\tP(Y = P | X=['N', 'P'] )=  0.1837\n",
      "\t==> Best is: N\n",
      "['P', 'N']\n",
      "Case  ['P', 'N']\n",
      "\tP(Y = N | X=['P', 'N'] )=  0.4098\n",
      "\tP(Y = P | X=['P', 'N'] )=  0.5902\n",
      "\t==> Best is: P\n",
      "['P', 'P']\n",
      "Case  ['P', 'P']\n",
      "\tP(Y = N | X=['P', 'P'] )=  0.1220\n",
      "\tP(Y = P | X=['P', 'P'] )=  0.8780\n",
      "\t==> Best is: P\n"
     ]
    }
   ],
   "source": [
    "data=[[\"N\", \"N\"], [\"N\", \"P\"], [\"P\", \"N\"], [\"P\", \"P\"]]\n",
    "for d in data:\n",
    "    res =calc_posterior(d, priors, L_hoods)\n",
    "    print(\"Case \", d)\n",
    "    cur_best=(-999,\"x\")\n",
    "    for yi in res:\n",
    "        if (res[yi], yi)>cur_best: cur_best=(res[yi], yi)\n",
    "        print(\"\\tP(Y = %s | X=%s )= %7.4f\"% (yi, d, res[yi]))        \n",
    "    print(\"\\t==> Best is:\", cur_best[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Test Naive-Bayes with Iris data\n",
    "\n",
    "Since our classifier only works with categorical data, we will load the iris data and discretize it \n",
    "\n",
    "Mote: this code implies that scikit-learn is already installed in the system. If that is not thecase, plese see below, section 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data=load_iris()\n",
    "cnames=data.feature_names\n",
    "X0=data.data\n",
    "class_names=data.target_names\n",
    "y_iris=data.target_names[data.target]\n",
    "X_iris=np.empty(X0.shape,dtype=\"object\")\n",
    "X_iris[:,:]=\"Medium\"\n",
    "for i,cname in enumerate(cnames):\n",
    "    q33, q67=np.quantile(X0[:,i], (0.33, 0.67))\n",
    "    X_iris[X0[:,i]<q33, i]=\"Small\"\n",
    "    X_iris[X0[:,i]>q67, i]=\"Large\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Take notice that we have 4 variables, each discretized in 3 intervals and 3 classes. \n",
    "1. Compute how many likelyhoods do we have to calculate?\n",
    "2. And how many priors?\n",
    "3. is it reasonable to expect that all likelyhoods have strict positive values? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors are:\n",
      "\tP(Y = setosa) =  0.3333\n",
      "\tP(Y = versicolor) =  0.3333\n",
      "\tP(Y = virginica) =  0.3333\n",
      "Likelyhoods:\n",
      "\tP(X0 = Large | Y = setosa) =  0.0000\n",
      "\tP(X0 = Large | Y = versicolor) =  0.2200\n",
      "\tP(X0 = Large | Y = virginica) =  0.6200\n",
      "\tP(X0 = Medium | Y = setosa) =  0.2000\n",
      "\tP(X0 = Medium | Y = versicolor) =  0.6800\n",
      "\tP(X0 = Medium | Y = virginica) =  0.3600\n",
      "\tP(X0 = Small | Y = setosa) =  0.8000\n",
      "\tP(X0 = Small | Y = versicolor) =  0.1000\n",
      "\tP(X0 = Small | Y = virginica) =  0.0200\n",
      "\tP(X1 = Large | Y = setosa) =  0.6600\n",
      "\tP(X1 = Large | Y = versicolor) =  0.0400\n",
      "\tP(X1 = Large | Y = virginica) =  0.1600\n",
      "\tP(X1 = Medium | Y = setosa) =  0.3200\n",
      "\tP(X1 = Medium | Y = versicolor) =  0.4200\n",
      "\tP(X1 = Medium | Y = virginica) =  0.4600\n",
      "\tP(X1 = Small | Y = setosa) =  0.0200\n",
      "\tP(X1 = Small | Y = versicolor) =  0.5400\n",
      "\tP(X1 = Small | Y = virginica) =  0.3800\n",
      "\tP(X2 = Large | Y = setosa) =  0.0000\n",
      "\tP(X2 = Large | Y = versicolor) =  0.0400\n",
      "\tP(X2 = Large | Y = virginica) =  0.8800\n",
      "\tP(X2 = Medium | Y = setosa) =  0.0000\n",
      "\tP(X2 = Medium | Y = versicolor) =  0.9600\n",
      "\tP(X2 = Medium | Y = virginica) =  0.1200\n",
      "\tP(X2 = Small | Y = setosa) =  1.0000\n",
      "\tP(X2 = Small | Y = versicolor) =  0.0000\n",
      "\tP(X2 = Small | Y = virginica) =  0.0000\n",
      "\tP(X3 = Large | Y = setosa) =  0.0000\n",
      "\tP(X3 = Large | Y = versicolor) =  0.0400\n",
      "\tP(X3 = Large | Y = virginica) =  0.9200\n",
      "\tP(X3 = Medium | Y = setosa) =  0.0000\n",
      "\tP(X3 = Medium | Y = versicolor) =  0.9600\n",
      "\tP(X3 = Medium | Y = virginica) =  0.0800\n",
      "\tP(X3 = Small | Y = setosa) =  1.0000\n",
      "\tP(X3 = Small | Y = versicolor) =  0.0000\n",
      "\tP(X3 = Small | Y = virginica) =  0.0000\n"
     ]
    }
   ],
   "source": [
    "#there are 4*3*3=36 likelyhoods to calculate (4 variable * 3 intervals * 3 classes)\n",
    "#there are 3 priors, the types of flower\n",
    "#not all likelyhoods are postive, some are zero, because the dataset doesn't have cases for those likelyhoods\n",
    "priors, L_hoods=PD_NB(X_iris,y_iris)\n",
    "show_NB(priors, L_hoods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medium', 'Large', 'Medium', 'Large']\n",
      "Instance:  ['Medium', 'Large', 'Medium', 'Large']\n",
      "\tP(Y = setosa | X=['Medium', 'Large', 'Medium', 'Large'] )=  0.0000\n",
      "\tP(Y = versicolor | X=['Medium', 'Large', 'Medium', 'Large'] )=  0.1411\n",
      "\tP(Y = virginica | X=['Medium', 'Large', 'Medium', 'Large'] )=  0.8589\n",
      "\t==> Best is: virginica\n",
      "['Small', 'Large', 'Small', 'Small']\n",
      "Instance:  ['Small', 'Large', 'Small', 'Small']\n",
      "\tP(Y = setosa | X=['Small', 'Large', 'Small', 'Small'] )=  1.0000\n",
      "\tP(Y = versicolor | X=['Small', 'Large', 'Small', 'Small'] )=  0.0000\n",
      "\tP(Y = virginica | X=['Small', 'Large', 'Small', 'Small'] )=  0.0000\n",
      "\t==> Best is: setosa\n"
     ]
    }
   ],
   "source": [
    "data=[[\"Medium\", \"Large\", \"Medium\", \"Large\"], [\"Small\", \"Large\", \"Small\", \"Small\"]]\n",
    "for d in data:\n",
    "    res =calc_posterior(d, priors, L_hoods)\n",
    "    print(\"Instance: \", d)\n",
    "    cur_best=(-999,\"x\")\n",
    "    for yi in res:\n",
    "        if (res[yi], yi)>cur_best: cur_best=(res[yi], yi)\n",
    "        print(\"\\tP(Y = %s | X=%s )= %7.4f\"% (yi, d, res[yi]))\n",
    "    print(\"\\t==> Best is:\", cur_best[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes in scikit-learn\n",
    "\n",
    "\n",
    "A typical machine learning procedure is executed in the following way\n",
    "\n",
    "0. Data is typically \n",
    "    * X - the set of independent variables as a numpy array\n",
    "    * y - the known values for the dependent variable as a corresponding 1D numpy array \n",
    "1. The full dataset is split into training and testing sets(we will expand on this later)\n",
    "2. One initializes an algorithm with a set of parameters \n",
    "    * `myModel=model(a=1, b=2,...)`\n",
    "3. The model is fit with the training set:\n",
    "    * `myModel.fit(X_train,y_train)`\n",
    "4. Predictions are made with the testing set\n",
    "    * `predictions=myModel.predict(X_test)`\n",
    "5. Classification statistics are computed\n",
    "\n",
    "\n",
    "For the Covid dataset we will not need a testing set as there are only four possible values, but we will follow the general procedure\n",
    "\n",
    "\n",
    "###  The Covid example\n",
    "\n",
    "\n",
    "#### Step 1 - get the training and testing data\n",
    "\n",
    "Let's process the data, by getting it out of the existing pandas dataframe. It is essential for most models that the data is numeric, so we will transform our data matrix into two columns with 0, and 1. Note that we use the pandas `get_dummies()` function, with the `drop_first= argument. True` to ensure that we have only one column and when the value is positive it is 1, otherwise it is 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "y_train: ['P' 'P' 'N' 'N' 'N' 'N' 'P' 'N' 'P' 'N' 'P' 'N' 'N' 'N']\n"
     ]
    }
   ],
   "source": [
    "X_df0 = df_covid.drop(columns=[\"Covid\"])\n",
    "X_df= pd.get_dummies(X_df0, drop_first=True)\n",
    "X_df.columns=X_df0.columns\n",
    "\n",
    "y_train = df_covid.values[:, 2]\n",
    "X_train = X_df.values[:,[0,1]]\n",
    "print(\"X_train:\", X_train) \n",
    "print(\"y_train:\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing set will be only our four possible cases (all possible combinations of tests A and B results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - set up the classifier\n",
    "\n",
    "\n",
    "For the current case with categorical values **only**, we can use [CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html), which treats each variable value as categorical. \n",
    "\n",
    "We can now build our classifier. Note that Laplace's `alpha` is used as a parameter, very close to zero, as our simple classifier does not make this correction. So we can compare the results of both methods for the 4 types of data.\n",
    "\n",
    "In this class we can use the classifier giving the most likely class using the `.predict(X)` method. however the `.predict_proba(X)` method returns an array with the probabilities of each class. The order of the columns is the alphabetical order of the classes, so the 1st column corresponds to class `N` and the 2nd to class `P` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "mdl=CategoricalNB(alpha=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Fit the model\n",
    "\n",
    "This is the easiest part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(X_train,y_train)\n",
    "\n",
    "#actually the fit method returns a copy of itself so we might write\n",
    "mdl = mdl.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Make predictions with the testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:  [0 0]\n",
      "\tP(Y = N | X=[0 0] )=  0.9569\n",
      "\tP(Y = P | X=[0 0] )=  0.0431\n",
      "Case:  [0 1]\n",
      "\tP(Y = N | X=[0 1] )=  0.8162\n",
      "\tP(Y = P | X=[0 1] )=  0.1838\n",
      "Case:  [1 0]\n",
      "\tP(Y = N | X=[1 0] )=  0.4099\n",
      "\tP(Y = P | X=[1 0] )=  0.5901\n",
      "Case:  [1 1]\n",
      "\tP(Y = N | X=[1 1] )=  0.1221\n",
      "\tP(Y = P | X=[1 1] )=  0.8779\n"
     ]
    }
   ],
   "source": [
    "#p2=mdl.predict(X_test)\n",
    "probas=mdl.predict_proba(X_test)\n",
    "for i, x in enumerate(probas):\n",
    "    print(\"Case: \", X_test[i])\n",
    "    for j, c in enumerate([\"N\", \"P\"]):\n",
    "        print(\"\\tP(Y = %s | X=%s )= %7.4f\"% (c, X_test[i], x[j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn Maive Bayes has of course the `.predict(X)` method that makes the classification directly, without going through the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:  [0 0] --> N\n",
      "Case:  [0 1] --> N\n",
      "Case:  [1 0] --> P\n",
      "Case:  [1 1] --> P\n"
     ]
    }
   ],
   "source": [
    "preds=mdl.predict(X_test)\n",
    "for i, p in enumerate(preds):\n",
    "    print(\"Case: \", X_test[i], \"-->\", p)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the test set, let's identify which lines are misclassified, and examine their classification probabilities by class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5\n",
    "\n",
    "For the base Iris data (before discretization) create a model [Naive Bayes Gaussian (Gaussian NB)](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) and test it with the same data partition. Comment on the results obtained, comparing them with the discrete model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score is:  0.94\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m preds\u001b[38;5;241m=\u001b[39mmdl\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Accuracy score is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, preds))\n\u001b[0;32m---> 12\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mconfusion_matrix\u001b[49m(y_test, preds), columns\u001b[38;5;241m=\u001b[39mclass_names, index\u001b[38;5;241m=\u001b[39mclass_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "#Solu√ß√£o Exerc√≠cio 5\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=6)\n",
    "\n",
    "mdl=GaussianNB()\n",
    "mdl.fit(X_train, y_train)\n",
    "\n",
    "preds=mdl.predict(X_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "pd.DataFrame(confusion_matrix(y_test, preds), columns=class_names, index=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gaussian Naive Bayes (optional - not evaluated)\n",
    "\n",
    "### 3.1. The essence of Bayesian classification in 1-Dimension\n",
    "\n",
    "Assuming a Gaussian distribution of the independent variable, In one dimension, it is very simple to make a Bayesian classifier. Given 2 classes A and B, the probability that instance i is in class A can be computed as the product of the likelyhood and the priors\n",
    "\n",
    "$P(i \\in Class_A | x_i) \\propto P(x_i |i \\in Class_A).P(Class_A)$\n",
    "\n",
    "$P(i \\in Class_B | x_i) \\propto P(x_i |i \\in Class_B).P(Class_B)$\n",
    "\n",
    "What makes a Bayesina classifier in this condition is the simple observation that the likelyhoods are proportional to the probability distribution functions\n",
    "\n",
    "So for instance if we have 2 gaussian distributions for class A and B, assuming identical priors, the optimal classification separation line is where both lines intersect\n",
    "\n",
    "So if we have a class A with mean = 2.0 and std =  0.5, and class B with mean = 3.5 and std=1.5, we can compute their distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "normA=norm(loc=2.0, scale=0.5)\n",
    "normB=norm(loc=3.5, scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And actually plot them on a given interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(-1, 8, 100)\n",
    "yA = normA.pdf(x)\n",
    "yB = normB.pdf(x)\n",
    "\n",
    "plt.plot(x, yA,'r-', lw=1, alpha=0.6, label='ClassA')\n",
    "plt.plot(x, yB,'b-', lw=1, alpha=0.6, label='ClassB')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually identify the regions that belong to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_regions=x[yA-yB>0]\n",
    "B_regions=x[yA-yB<=0]\n",
    "plt.scatter(A_regions, np.ones(A_regions.size), c=\"b\", label=\"Class A\")\n",
    "plt.scatter(B_regions, -np.ones(B_regions.size), c=\"r\", label=\"Class B\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualise a 2 dimensional classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train=pd.read_csv(\"train.csv\")\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df_train[\"cl\"]\n",
    "y_train=np.array(y_train, dtype=\"U\")\n",
    "X_train=df_train.values[:,0:2]\n",
    "X_train=X_train.astype(float)\n",
    "\n",
    "y_test=df_test[\"cl\"]\n",
    "y_test=y_test.astype(\"U\") #need to update the type\n",
    "X_test=df_test.values[:,0:2]\n",
    "X_test=X_test.astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train[y_train==\"A\",0], X_train[y_train==\"A\",1], label=\"Class A\")\n",
    "plt.scatter(X_train[y_train==\"B\",0], X_train[y_train==\"B\",1], label=\"Class B\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the global statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2 = np.mean(X_train, axis=0)\n",
    "v1, v2 = np.var(X_train, axis=0)\n",
    "s1, s2 = np.sqrt(np.array([v1, v2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check just the difference in mean dan stddev for the first variable (column = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cA=X_test[y_test==\"A\", 0]\n",
    "cB=X_test[y_test==\"B\", 0]\n",
    "\n",
    "mA =np.mean(cA)\n",
    "mB =np.mean(cB)\n",
    "sA=np.sqrt(np.var(cA))\n",
    "sB=np.sqrt(np.var(cB))\n",
    "print( \"For class A, the mean is %6.3f and the stdev is %6.3f\" % (mA, sA))\n",
    "print( \"For class B, the mean is %6.3f and the stdev is %6.3f\" % (mB, sB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the above procedure we can similarly compute the normals and check them visually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that each class is equally likely we can plot the Gaussians of both classes.\n",
    "\n",
    "We can see that that point around -0.38 is what separates the highest likelyhoo of a new random instance belonging to a given class\n",
    "\n",
    "* It is class A if $x > -0.32 $\n",
    "* It is class B if $x\\leq -0.32 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(m1-3*s1, m1+3*s1, 100)\n",
    "normA=norm(loc=mA, scale=sA)\n",
    "normB=norm(loc=mB, scale=sB)\n",
    "yA = normA.pdf(x)\n",
    "yB = normB.pdf(x)\n",
    "\n",
    "plt.plot(x, yA,'r-', lw=1, alpha=0.6, label='ClassA')\n",
    "plt.plot(x, yB,'b-', lw=1, alpha=0.6, label='ClassB')\n",
    "plt.axvline(-0.38)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be true if the priors of both classes we know they are not as it depends on the representativity of each class which could actually be computed in a very simple way, anthough numpy has other more sofisticated ways to do so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nA=np.sum(y_test==\"A\")\n",
    "nB=np.sum(y_test==\"B\")\n",
    "priorA, priorB = nA/(nA+nB), nB/(nA+nB), \n",
    "priorA, priorB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now know that actually class A is much more representative than class B, and we can update our model accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yA = normA.pdf(x)*priorA\n",
    "yB = normB.pdf(x)*priorB\n",
    "\n",
    "plt.plot(x, yA,'r-', lw=1, alpha=0.6, label='ClassA')\n",
    "plt.plot(x, yB,'b-', lw=1, alpha=0.6, label='ClassB')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now see that actually class A actually is much more dominant, and appearing on two areas of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_regions=x[yA-yB>0]\n",
    "B_regions=x[yA-yB<=0]\n",
    "plt.scatter(A_regions, np.ones(A_regions.size), c=\"b\", label=\"Class A\")\n",
    "plt.scatter(B_regions, -np.ones(B_regions.size), c=\"r\", label=\"Class B\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one variable and assuming that the distribution for both classes is Gaussian this is the actually Optimal Bayesian classifier and we can actually use these for classification\n",
    "\n",
    "Using the testing set, we just compute the respective likelihoods of both classes and multiply by the priors and the class predicted is just when the value of one class is larger than the other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yA = normA.pdf(X_test[:,0])*priorA\n",
    "yB = normB.pdf(X_test[:,0])*priorB\n",
    "preds=np.array([\"A\", \"B\"])[np.array(yA<=yB, dtype=int)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(\"The global accuracy is: %7.4f\" % accuracy_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Combining multiple quantitative dimensions\n",
    "\n",
    "The above describes a Gaussian Bayesian classifier. For Naive Bayes we need to do as we have done above for categorical data. We need to compute the priors and the likelyhoods for each variable and class\n",
    "\n",
    "$P(i \\in Class_A | x_i) \\propto \\prod_j{P(x_{ij} |i \\in Class_A)}.P(Class_A)$\n",
    "\n",
    "$P(i \\in Class_B | x_i)  \\propto \\prod_j{P(x_{ij} |i \\in Class_B)}.P(Class_B)$\n",
    "\n",
    "Therefore we need some functions that, given any dataset, are able to:\n",
    "\n",
    "* compute overal statistics for parametrization of the Gaussians and priors `get_class_stats()`\n",
    "* compute the Gaussian functions given the stats for each class `get_gaussians()`\n",
    "* Compute the priors given the priors `get_priors()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will compute the means and std deviations for all classes\n",
    "def get_class_stats(X, y):\n",
    "    classes=list(set(y))\n",
    "    N,M=X.shape\n",
    "    stats={c: None for c in classes}\n",
    "    for c in classes:\n",
    "        mX = X[y==c,:]\n",
    "        means = np.mean(mX, axis=0)\n",
    "        stds  = np.sqrt(np.var(mX, axis=0))\n",
    "        count,_=mX.shape\n",
    "        stats[c]=(count, means, stds)\n",
    "    return stats\n",
    "    \n",
    "#this function will get all the gaussians: One for each variable, class combination\n",
    "def get_gaussians(stats):\n",
    "    gaussians={}\n",
    "    for c in stats:\n",
    "        N, means, stds=stats[c]\n",
    "        gaussians[c]=[norm(loc=mean, scale=stds[i]) for i, mean in enumerate(means)]\n",
    "    return gaussians\n",
    "\n",
    "def get_priors(stats):\n",
    "    priors = {}\n",
    "    total  = 0\n",
    "    for c in stats:\n",
    "        N, means, stds=stats[c]\n",
    "        priors[c]=N\n",
    "        total+=N\n",
    "    for c in priors: priors[c]/=total\n",
    "    return priors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will further require a function that given a dataset, the priors and the gaussians is able to make a prediction for each row of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnb_predict(Xtst, priors, gaussians):\n",
    "    N,M = Xtst.shape\n",
    "    res         = -np.ones(N)\n",
    "    final_preds = -np.zeros(N)\n",
    "    final_preds=final_preds.astype(str)\n",
    "    for c in gaussians:\n",
    "        preds=np.ones(N)*priors[c]\n",
    "        for col in range(M): preds*=gaussians[c][col].pdf(Xtst[:,col])\n",
    "        final_preds[preds>res]=c\n",
    "        res[preds>res]=preds[preds>res]\n",
    "    return final_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample use for our very simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_class_stats(X_train,y_train)\n",
    "gaussians= get_gaussians(stats)\n",
    "priors = get_priors(stats)\n",
    "\n",
    "preds = gnb_predict(X_test, priors, gaussians)\n",
    "print(\"The global accuracy is: %7.4f\" % accuracy_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try the Iris and see how our classifier works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_iris, y_iris = load_iris(return_X_y = True) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris,y_iris, test_size=0.33, random_state=22)\n",
    "\n",
    "stats = get_class_stats(X_train,y_train)\n",
    "gaussians= get_gaussians(stats)\n",
    "priors = get_priors(stats)\n",
    "preds = gnb_predict(X_test, priors, gaussians)\n",
    "preds=preds.astype(int)  #we need to convert the data to integers\n",
    "print(\"The global accuracy is: %7.4f\" % accuracy_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
